{smcl}
{com}{sf}{ul off}{txt}{.-}
      name:  {res}<unnamed>
       {txt}log:  {res}D:\Data\data_FADNPanelAnalysis\Do_Files\multisward\logs/multisward2013_08_01.txt
  {txt}log type:  {res}smcl
 {txt}opened on:  {res} 1 Aug 2013, 19:55:52
{txt}
{com}. di  "Job  Started  at  $S_TIME  on $S_DATE"
{res}Job  Started  at  19:55:52  on  1 Aug 2013
{txt}
{com}. cmdlog using logs/$project$datestamp.cmd.txt, replace
{txt}(cmdlog D:\Data\data_FADNPanelAnalysis\Do_Files\multisward\logs/multisward2013_08_01.cmd.txt opened)

{com}. 
. 
. 
. if `tests' == 1 {c -(}
. 
. 
.         qui xtreg `dep_vlist' `indep_vlist', fe
.         estimates store fixed
.         
.         
.         qui xtreg `dep_vlist' `indep_vlist', re
.         estimates store random
.         
.         
.         /* Hausman specification test 
>             H0: difference in coef not systematic (use RE) */ 
.         qui hausman fixed random
.         local hausman_test = "Prob>chi2 = `r(p)'"
.         
.         
.         /* Test for time fixed effects 
>             H0: Joint test of year effects =0   */ 
.         qui xtreg `dep_vlist' `indep_vlist' i.year, fe
.         qui testparm i.year
.         local time_FE = "Prob>F = `r(p)'"
.         
.         
.         /* Breusch-Pagan LM test of RE vs OLS 
>             H0: Variances across entities are 0 
>               (i.e. no panel effect)            */ 
.         estimates restore random
.         qui xttest0
.         local BreuschPagan_LM_RE = "Prob>chi2 = `r(p)'"
.         
.         
.         /* Wald test for groupwise heteroscedasticity (for FE)
>              H0: Constant variance (i.e. homoscedasticity   */ 
.         estimates restore fixed
.         qui xttest3
.         local wald_heterosc = "Prob>chi2 = `r(p)'"
. 
. 
. {c )-}
{txt}
{com}. 
. 
. keep `dep_vlist' `indep_vlist' `z_vlist' pid year farmcode country
{txt}
{com}. set matsize 5000
{txt}
{com}. 
. * model you selected above is run here
. macro list _model1command
{txt}{p 0 16}
_model1command:{space 1}{res}{res}sfpanel lntotalinputs lndotomkgl  lnPLand lnPTotalCattle lnPLabour  if country=="IRE" , model(tfe) cost d(tnormal) emean(hasreps fdratio, noconstant)  usigma(hasreps fdratio, noconstant) vsigma(hasreps fdratio, noconstant)
{p_end}
{txt}
{com}. `model1command' 

{res}
{txt}initial:{col 16}Log likelihood = {res:-1546.8671}
Iteration 0:{space 3}Log likelihood = {res:-1546.8671}  (not concave)
Iteration 1:{space 3}Log likelihood = {res:-622.25756}  (not concave)
Iteration 2:{space 3}Log likelihood = {res:-206.82406}  (not concave)
Iteration 3:{space 3}Log likelihood = {res:-84.464135}  (not concave)
Iteration 4:{space 3}Log likelihood = {res: 107.56595}  (not concave)
Iteration 5:{space 3}Log likelihood = {res: 245.99315}  (not concave)
Iteration 6:{space 3}Log likelihood = {res: 299.12967}  (not concave)
Iteration 7:{space 3}Log likelihood = {res:  361.1773}  (not concave)
Iteration 8:{space 3}Log likelihood = {res: 512.67951}  (not concave)
Iteration 9:{space 3}Log likelihood = {res: 515.16443}  (not concave)
Iteration 10:{space 2}Log likelihood = {res: 530.99132}  (not concave)
Iteration 11:{space 2}Log likelihood = {res: 534.25787}  (not concave)
Iteration 12:{space 2}Log likelihood = {res: 535.57305}  (not concave)
Iteration 13:{space 2}Log likelihood = {res: 550.13589}  (not concave)
Iteration 14:{space 2}Log likelihood = {res: 553.63458}  (not concave)
Iteration 15:{space 2}Log likelihood = {res: 564.91611}  (not concave)
Iteration 16:{space 2}Log likelihood = {res: 565.57293}  (not concave)
Iteration 17:{space 2}Log likelihood = {res: 589.08702}  (not concave)
Iteration 18:{space 2}Log likelihood = {res: 605.26539}  (not concave)
Iteration 19:{space 2}Log likelihood = {res: 668.18548}  (not concave)
Iteration 20:{space 2}Log likelihood = {res:  668.2619}  (not concave)
Iteration 21:{space 2}Log likelihood = {res: 671.71375}  (not concave)
Iteration 22:{space 2}Log likelihood = {res: 764.56322}  (not concave)
Iteration 23:{space 2}Log likelihood = {res: 764.70826}  (not concave)
Iteration 24:{space 2}Log likelihood = {res: 764.82432}  (not concave)
Iteration 25:{space 2}Log likelihood = {res: 764.91656}  (not concave)
Iteration 26:{space 2}Log likelihood = {res:  766.0641}  (not concave)
Iteration 27:{space 2}Log likelihood = {res: 779.66817}  (not concave)
Iteration 28:{space 2}Log likelihood = {res: 801.80001}  (not concave)
Iteration 29:{space 2}Log likelihood = {res: 802.28771}  (not concave)
Iteration 30:{space 2}Log likelihood = {res: 846.92499}  (not concave)
Iteration 31:{space 2}Log likelihood = {res: 858.40267}  (not concave)
Iteration 32:{space 2}Log likelihood = {res: 858.40709}  (not concave)
Iteration 33:{space 2}Log likelihood = {res: 858.43476}  (not concave)
Iteration 34:{space 2}Log likelihood = {res: 880.12549}  (not concave)
Iteration 35:{space 2}Log likelihood = {res: 880.12603}  (not concave)
Iteration 36:{space 2}Log likelihood = {res: 880.13953}  (not concave)
Iteration 37:{space 2}Log likelihood = {res: 883.76992}  (not concave)
Iteration 38:{space 2}Log likelihood = {res: 927.32767}  
Iteration 39:{space 2}Log likelihood = {res:  927.4898}  (backed up)
Iteration 40:{space 2}Log likelihood = {res: 943.01825}  (not concave)
Iteration 41:{space 2}Log likelihood = {res: 987.36354}  (not concave)
Iteration 42:{space 2}Log likelihood = {res: 987.36468}  (not concave)
Iteration 43:{space 2}Log likelihood = {res: 987.36551}  
Iteration 44:{space 2}Log likelihood = {res: 988.25241}  (backed up)
Iteration 45:{space 2}Log likelihood = {res: 990.88579}  (backed up)
Iteration 46:{space 2}Log likelihood = {res: 992.24271}  (backed up)
Iteration 47:{space 2}Log likelihood = {res:  992.3601}  (backed up)
Iteration 48:{space 2}Log likelihood = {res: 1012.1558}  (backed up)
Iteration 49:{space 2}Log likelihood = {res: 1015.1678}  (backed up)
Iteration 50:{space 2}Log likelihood = {res:  1015.764}  (backed up)
Iteration 51:{space 2}Log likelihood = {res: 1040.8156}  
Iteration 52:{space 2}Log likelihood = {res: 1053.5822}  (not concave)
Iteration 53:{space 2}Log likelihood = {res: 1144.8819}  (not concave)
Iteration 54:{space 2}Log likelihood = {res:  1144.882}  (not concave)
Iteration 55:{space 2}Log likelihood = {res: 1144.8821}  (not concave)
Iteration 56:{space 2}Log likelihood = {res:  1144.884}  (not concave)
Iteration 57:{space 2}Log likelihood = {res: 1144.8848}  (not concave)
Iteration 58:{space 2}Log likelihood = {res: 1144.8959}  (not concave)
Iteration 59:{space 2}Log likelihood = {res: 1144.9561}  (not concave)
Iteration 60:{space 2}Log likelihood = {res: 1145.0042}  (not concave)
Iteration 61:{space 2}Log likelihood = {res: 1145.0426}  (not concave)
Iteration 62:{space 2}Log likelihood = {res: 1145.2882}  (not concave)
Iteration 63:{space 2}Log likelihood = {res: 1145.3374}  (not concave)
Iteration 64:{space 2}Log likelihood = {res:  1145.415}  (not concave)
Iteration 65:{space 2}Log likelihood = {res:  1145.904}  (not concave)
Iteration 66:{space 2}Log likelihood = {res:  1155.601}  (not concave)
Iteration 67:{space 2}Log likelihood = {res: 1159.3205}  (not concave)
Iteration 68:{space 2}Log likelihood = {res: 1178.1963}  (not concave)
Iteration 69:{space 2}Log likelihood = {res: 1178.1963}  (not concave)
Iteration 70:{space 2}Log likelihood = {res: 1178.2083}  (not concave)
Iteration 71:{space 2}Log likelihood = {res: 1179.3781}  (not concave)
Iteration 72:{space 2}Log likelihood = {res: 1179.6101}  (not concave)
Iteration 73:{space 2}Log likelihood = {res: 1187.2139}  (not concave)
Iteration 74:{space 2}Log likelihood = {res: 1187.2185}  (not concave)
Iteration 75:{space 2}Log likelihood = {res: 1187.6878}  (not concave)
Iteration 76:{space 2}Log likelihood = {res: 1197.4349}  (not concave)
Iteration 77:{space 2}Log likelihood = {res: 1197.4349}  (not concave)
Iteration 78:{space 2}Log likelihood = {res: 1197.4364}  (not concave)
Iteration 79:{space 2}Log likelihood = {res: 1197.5446}  (not concave)
Iteration 80:{space 2}Log likelihood = {res: 1202.8747}  (not concave)
Iteration 81:{space 2}Log likelihood = {res: 1204.3411}  (not concave)
Iteration 82:{space 2}Log likelihood = {res: 1212.8091}  (not concave)
Iteration 83:{space 2}Log likelihood = {res: 1212.8091}  (not concave)
Iteration 84:{space 2}Log likelihood = {res: 1212.8095}  (not concave)
Iteration 85:{space 2}Log likelihood = {res: 1212.8468}  (not concave)
Iteration 86:{space 2}Log likelihood = {res: 1214.5536}  (not concave)
Iteration 87:{space 2}Log likelihood = {res: 1219.7594}  (not concave)
Iteration 88:{space 2}Log likelihood = {res: 1220.0199}  (not concave)
Iteration 89:{space 2}Log likelihood = {res: 1226.3472}  (not concave)
Iteration 90:{space 2}Log likelihood = {res: 1226.3474}  (not concave)
Iteration 91:{space 2}Log likelihood = {res: 1226.3551}  (not concave)
Iteration 92:{space 2}Log likelihood = {res:   1226.75}  (not concave)
Iteration 93:{space 2}Log likelihood = {res:  1231.684}  (not concave)
Iteration 94:{space 2}Log likelihood = {res: 1231.6917}  (not concave)
Iteration 95:{space 2}Log likelihood = {res: 1232.0834}  (not concave)
Iteration 96:{space 2}Log likelihood = {res:  1234.503}  (not concave)
Iteration 97:{space 2}Log likelihood = {res:  1234.745}  (not concave)
Iteration 98:{space 2}Log likelihood = {res: 1240.5423}  (not concave)
Iteration 99:{space 2}Log likelihood = {res: 1240.5423}  (not concave)
Iteration 100:{space 1}Log likelihood = {res: 1240.5427}  (not concave)

True fixed-effects model (truncated-normal){col 54}Number of obs {col 68}={col 70}{res}     1141
{txt}Group variable: {res}pid{txt}{col 51}Number of groups{col 68}={col 70}{res}      315
{txt}Time variable: {res}year{txt}{col 49}Obs per group: min{col 68}={col 70}{res}        1
{col 64}{txt}avg{col 68}={col 70}{res}      3.6
{col 64}{txt}max{col 68}={col 70}{res}        9

{txt}{col 54}Prob > chi2   = {res}   0.0000
{txt}Log likelihood = {res} 1240.5427{txt}{col 54}Wald chi2({res}1{txt})  = {res} 6.20e+08

{txt}{hline 15}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{col 1} lntotalinputs{col 16}{c |}      Coef.{col 28}   Std. Err.{col 40}      z{col 48}   P>|z|{col 56}     [95% Con{col 69}f. Interval]
{hline 15}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}Frontier       {txt}{c |}
{space 4}lndotomkgl {c |}{col 16}{res}{space 2} .8392016{col 28}{space 2}  .000032{col 39}{space 1} 2.6e+04{col 48}{space 3}0.000{col 56}{space 4} .8391389{col 69}{space 3} .8392643
{txt}{space 7}lnPLand {c |}{col 16}{res}{space 2}   .04272{col 28}{space 2}        .{col 39}{space 1}       .{col 48}{space 3}    .{col 56}{space 4}        .{col 69}{space 3}        .
{txt}lnPTotalCattle {c |}{col 16}{res}{space 2}  .231837{col 28}{space 2}        .{col 39}{space 1}       .{col 48}{space 3}    .{col 56}{space 4}        .{col 69}{space 3}        .
{txt}{space 5}lnPLabour {c |}{col 16}{res}{space 2} .0557992{col 28}{space 2}        .{col 39}{space 1}       .{col 48}{space 3}    .{col 56}{space 4}        .{col 69}{space 3}        .
{txt}{hline 15}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}Mu             {txt}{c |}
{space 7}hasreps {c |}{col 16}{res}{space 2}-13.50961{col 28}{space 2} 5.837853{col 39}{space 1}   -2.31{col 48}{space 3}0.021{col 56}{space 4} -24.9516{col 69}{space 3} -2.06763
{txt}{space 7}fdratio {c |}{col 16}{res}{space 2}-74.76022{col 28}{space 2} 5.896369{col 39}{space 1}  -12.68{col 48}{space 3}0.000{col 56}{space 4}-86.31689{col 69}{space 3}-63.20355
{txt}{hline 15}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}Usigma         {txt}{c |}
{space 7}hasreps {c |}{col 16}{res}{space 2} .7837218{col 28}{space 2}  .214664{col 39}{space 1}    3.65{col 48}{space 3}0.000{col 56}{space 4}  .362988{col 69}{space 3} 1.204456
{txt}{space 7}fdratio {c |}{col 16}{res}{space 2} 2.464993{col 28}{space 2} .2762752{col 39}{space 1}    8.92{col 48}{space 3}0.000{col 56}{space 4} 1.923503{col 69}{space 3} 3.006482
{txt}{hline 15}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
{res}Vsigma         {txt}{c |}
{space 7}hasreps {c |}{col 16}{res}{space 2}-10.26021{col 28}{space 2} 3.055281{col 39}{space 1}   -3.36{col 48}{space 3}0.001{col 56}{space 4}-16.24845{col 69}{space 3}-4.271971
{txt}{space 7}fdratio {c |}{col 16}{res}{space 2}-85.31424{col 28}{space 2} 5.558787{col 39}{space 1}  -15.35{col 48}{space 3}0.000{col 56}{space 4}-96.20927{col 69}{space 3}-74.41922
{txt}{hline 15}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}
  E(sigma_u) {c |}  {res} 1.473412                                 1.453242    1.493582
{txt}  E(sigma_v) {c |}  {res} .0304566                                  .021818    .0390952
{txt}{hline 13}{c BT}{hline 64}

{com}. 
. 
. * store estimates and predict ind. TE scores
. qui estimates store `model1name'
{txt}
{com}. qui estimates save  `model1name'$datestamp.ster, replace
{txt}
{com}. qui capture drop te_`model1name'
{txt}
{com}. qui predict te_`model1name', `predict_opts'
{txt}
{com}. 
. 
. * constructs ind. level CI's for TE scores
. qui frontier_teci te_`model1name'_ci 
{txt}
{com}. 
. /*
> * store estimates and predict ind. TE scores
> qui estimates store `model2name'
> qui estimates save  `model2name'$datestamp.ster, replace
> qui capture drop te_`model2name'
> qui predict te_`model2name', `predict_opts'
> */
. 
. save `fadnoutdatadir'/$datanameSFA_post, replace
{txt}file D:\\Data/data_FADNPanelAnalysis/OutData/multisward/.dta saved

{com}. 
. 
. ********************************************************
. * End of MODELLING section              
. ********************************************************
. 
. 
. 
. 
. 
. 
. 
. 
. 
. ********************************************************
. * GENERATING DESCRIPTIVES 
. ********************************************************
. 
. * for supporting discussion of positive sign on hasreps in
. * production function (unexpected)
. corr `dep_vlist' `indep_vlist'
{txt}(obs=8148)

             {c |} lntota~s lndoto~l  lnPLand lnPTot~e lnPLab~r
{hline 13}{c +}{hline 45}
lntotalinp~s {c |}{res}   1.0000
  {txt}lndotomkgl {c |}{res}   0.9201   1.0000
     {txt}lnPLand {c |}{res}   0.0199   0.1222   1.0000
{txt}lnPTotalCa~e {c |}{res}   0.1654   0.1273  -0.1479   1.0000
   {txt}lnPLabour {c |}{res}   0.1480   0.1456   0.0020   0.1470   1.0000

{txt}
{com}. 
. 
. * some descriptives of the TE scores
. tabstat te_`model1name', stats(mean sem) by(country)

{txt}Summary for variables: te_tfe
{col 6}by categories of: country (a24)

{ralign 7:country} {...}
{c |}      mean  se(mean)
{hline 8}{c +}{hline 20}
{ralign 7:DEU} {...}
{c |}{...}
 {res}        .         .
{txt}{ralign 7:FRA} {...}
{c |}{...}
 {res}        .         .
{txt}{ralign 7:IRE} {...}
{c |}{...}
 {res} .8898103  .0032733
{txt}{ralign 7:UKI} {...}
{c |}{...}
 {res}        .         .
{txt}{hline 8}{c +}{hline 20}
{ralign 7:Total} {...}
{c |}{...}
 {res} .8898103  .0032733
{txt}{hline 8}{c BT}{hline 20}

{com}. 
. * describes the relationsip of fdratio to te_tfe
. tw (sc te_tfe fdratio) (lfit te_tfe fdratio, lwidth(thick))  if country=="IRE"
{res}{txt}
{com}. ** shows weak relation to mean, but stronger for heterscedasiticy
. ** therefore, put z's into sigma_u
. ********************************************************
. * End of GENERATING DESCRIPTIVES section
. ********************************************************
. 
. 
. 
. 
. 
. 
. 
. 
. 
. ********************************************************
. * CLEANING UP             
. ********************************************************
. 
. * report the model parameters you selected in the log
. capture macro list _dep_vlist _indep_vlist _location_vlist _model1command _model1name _predict_opts databuild ms sectors dataname datadir project 
{txt}
{com}. 
. 
. *clear
. capture erase blank.dta
{txt}
{com}. capture log close
{smcl}
{com}{sf}{ul off}